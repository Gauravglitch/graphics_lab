{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65feb004",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call here. Maybe you meant '==' instead of '='? (1085577859.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 58\u001b[1;36m\u001b[0m\n\u001b[1;33m    tick_mark() = range(len(iris.target_names))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "#decision tree ra plot tree library lai import gareko from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree \n",
    "#iris dataset lai import gareko from sklearn.datasets,iris dataset vaneko chai hellow world for data science\n",
    "from sklearn.datasets import load_iris\n",
    "#train test split model library lai import gareko from sklearn.models_selection for distrubting data \n",
    "from sklearn.model_selection import train_test_split\n",
    "#accuracy score library import gareko from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "#ploting library laichai import gareko as plt, for visualization in python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris= load_iris()\n",
    "X= iris.data\n",
    "y= iris.target\n",
    "\n",
    "#split the dataset into traning and testing sets\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#create a Decesion tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#train the model \n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#Make the prediction on the test set\n",
    "predictions=clf.predict(X_test)\n",
    "\n",
    "#calculate accuracy_score\n",
    "accuracy=accuracy_score(y_test,predictions)\n",
    "print(\"Decesion Accuracy:\",accuracy)\n",
    "\n",
    "#calculate precision\n",
    "precision=precision_score(y_test,predictions,average ='marco')\n",
    "print(\"precision:\",precision)\n",
    "\n",
    "#calculate recall\n",
    "recall=recall_score(y_test,predictions,average ='marco')\n",
    "print(\"recall:\",recall)\n",
    "\n",
    "#calculate f1_score\n",
    "f1=f1_score(y_test,predictions,average ='marco')\n",
    "print(\"f1_score:\",f1_score)\n",
    "    \n",
    "# calculate confusion_matrix\n",
    "confusion_mat=confusion_matrix(y_test, predictions)\n",
    "\n",
    "#plot the decision tree\n",
    "plt.figure(figsize=(10,8))\n",
    "plot_tree(clf,feature_names=iris.feature_names, class_names=iris.target_names,filled=True)\n",
    "plt.show()\n",
    "\n",
    "#visualize the confusion matrix\n",
    "plt.figure(fig_size=(8,6))\n",
    "plt.imshow(confusion_mat,interpolation='nearest',cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_mark() = range(len(iris.target_names))\n",
    "plt.xticks(tick_marks,iris.target_names)\n",
    "plt.yticks(tick_marks,iris.target_names)\n",
    "plt.xlabel('predicted label')\n",
    "plt.ylabel('true label')\n",
    "for i in range (confusion_mat.shape[0]):\n",
    "      for j in range (confusion_mat.shape[1]):\n",
    "          plt.text(j,i,confusion[i,j],horizontalalignment='center',color='white' if confusion_mat[i,j]>confusion_mat.max()/2 else \"black\")\n",
    "plt.show()      \n",
    "                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
